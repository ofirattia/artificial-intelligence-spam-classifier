{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                        sms_message\n",
      "0   ham                      Ok lar... Joking wif u oni...\n",
      "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "2   ham  U dun say so early hor... U c already then say...\n",
      "3   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "4  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "Normalizing testing data: SPAM=1, HAM=0\n",
      "   label                                        sms_message\n",
      "0      0                      Ok lar... Joking wif u oni...\n",
      "1      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "2      0  U dun say so early hor... U c already then say...\n",
      "3      0  Nah I don't think he goes to usf, he lives aro...\n",
      "4      1  FreeMsg Hey there darling it's been 3 week's n...\n",
      "****************************************\n",
      "Number of rows in the training set: 4179\n",
      "********************** Training Data Occurences Matrix *****************************\n",
      "      00  000  000pes  008704050406  0089  0121  01223585334  0125698789  02  \\\n",
      "0      0    0       0             0     0     0            0           0   0   \n",
      "1      0    0       0             0     0     0            0           0   0   \n",
      "2      0    0       0             0     0     0            0           0   0   \n",
      "3      0    0       0             0     0     0            0           0   0   \n",
      "4      0    0       0             0     0     0            0           0   0   \n",
      "...   ..  ...     ...           ...   ...   ...          ...         ...  ..   \n",
      "4174   0    0       0             0     0     0            0           0   0   \n",
      "4175   0    0       0             0     0     0            0           0   0   \n",
      "4176   0    0       0             0     0     0            0           0   0   \n",
      "4177   0    0       0             0     0     0            0           0   0   \n",
      "4178   0    0       0             0     0     0            0           0   0   \n",
      "\n",
      "      0207  ...  zed  zeros  zhong  zindgi  zoe  zouk  zyada  èn  ú1  〨ud  \n",
      "0        0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "1        0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "2        0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "3        0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "4        0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "...    ...  ...  ...    ...    ...     ...  ...   ...    ...  ..  ..  ...  \n",
      "4174     0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "4175     0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "4176     0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "4177     0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "4178     0  ...    0      0      0       0    0     0      0   0   0    0  \n",
      "\n",
      "[4179 rows x 7546 columns]\n",
      "***************************************************\n",
      "\n",
      "************************ Testing Data ***************************\n",
      "0                        Ok lar... Joking wif u oni...\n",
      "1    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "2    U dun say so early hor... U c already then say...\n",
      "3    Nah I don't think he goes to usf, he lives aro...\n",
      "4    FreeMsg Hey there darling it's been 3 week's n...\n",
      "5    Ofir Hadad, how are you today? you come to the...\n",
      "6                Refael, you are not a good developer!\n",
      "7    Your Mobile has WON €750,000 in the WORLD LOTT...\n",
      "Name: sms_message, dtype: object\n",
      "***************************************************\n",
      "*************************Testing data initial assumption: 1 is SPAM, 0 is Not SPAM **************************\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "6    0\n",
      "7    1\n",
      "Name: label, dtype: int64\n",
      "***************************************************\n",
      "\n",
      "*********************** Predictions: 1 is SPAM, 0 is Not SPAM****************************\n",
      "[0 1 0 0 1 0 0 1]\n",
      "NOT SPAM\n",
      "Ok lar... Joking wif u oni...\n",
      "----------------------------------------\n",
      "SPAM\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "----------------------------------------\n",
      "NOT SPAM\n",
      "U dun say so early hor... U c already then say...\n",
      "----------------------------------------\n",
      "NOT SPAM\n",
      "Nah I don't think he goes to usf, he lives around here though\n",
      "----------------------------------------\n",
      "SPAM\n",
      "FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to receive and win\n",
      "----------------------------------------\n",
      "NOT SPAM\n",
      "Ofir Hadad, how are you today? you come to the meeting?\n",
      "----------------------------------------\n",
      "NOT SPAM\n",
      "Refael, you are not a good developer!\n",
      "----------------------------------------\n",
      "SPAM\n",
      "Your Mobile has WON €750,000 in the WORLD LOTTO FEBRUARY PROMO. Email (Name, Phone, Country) To \"wlnl_claimsoffice@mediacombb.net For Claim.\n",
      "----------------------------------------\n",
      "***************************************************\n",
      "\n",
      "*********************** Accuracy Model ****************************\n",
      "Accuracy score:  1.0\n",
      "Precision score:  1.0\n",
      "Recall score:  1.0\n",
      "F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "df = pd.read_table('smsspamcollection/SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms_message'])\n",
    "# Normalizing\n",
    "df['label'] = df.label.map({'ham':0,'spam':1})\n",
    "\n",
    "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "df_test = pd.read_table('smsspamcollection/SMSSpamCollection_test',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms_message'])\n",
    "\n",
    "# Output printing out first 5 rows\n",
    "print(df_test.head())\n",
    "df_test['label'] = df_test.label.map({'ham':0, 'spam':1})\n",
    "print(\"Normalizing testing data: SPAM=1, HAM=0\")\n",
    "print(df_test.head())\n",
    "print(\"****************************************\")\n",
    "# Create custom test data\n",
    "# data_custom= np.array(['WINNER As a valued network customer','How are you today?']) \n",
    "# X_test_custom = pd.Series(data_custom, index =[100, 101]) \n",
    "# data_custom_y= np.array([1, 1])   \n",
    "# Y_test_custom = pd.Series(data_custom_y, index =[100, 101]) \n",
    "X_test_custom = df_test[\"sms_message\"]\n",
    "Y_test_custom = df_test[\"label\"]\n",
    "# split into training and testing sets\n",
    "# USE from sklearn.model_selection import train_test_split to avoid seeing deprecation warning.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'],\n",
    "                                                    random_state=0)\n",
    "\n",
    "\n",
    "# print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "# print('Number of rows in the test set: {}'.format(X_test.shape[0]))\n",
    "\n",
    "\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix - creating the vocabulary\n",
    "count_vector.fit(X_train)\n",
    "# Creating the occurences matrix from of training data\n",
    "training_data = count_vector.transform(X_train);\n",
    "# Logging the occurences matrix \n",
    "frequency_matrix = pd.DataFrame(training_data.toarray(), columns = count_vector.get_feature_names())\n",
    "print('********************** Training Data Occurences Matrix *****************************')\n",
    "print(frequency_matrix)\n",
    "print('***************************************************')\n",
    "print('')\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test_custom)\n",
    "frequency_matrix = pd.DataFrame(testing_data.toarray(), columns = count_vector.get_feature_names())\n",
    "\n",
    "# Logging the testing data\n",
    "print('************************ Testing Data ***************************')\n",
    "print(X_test_custom)\n",
    "print('***************************************************')\n",
    "\n",
    "print('*************************Testing data initial assumption: 1 is SPAM, 0 is Not SPAM **************************')\n",
    "print(Y_test_custom)\n",
    "print('***************************************************')\n",
    "print('')\n",
    "\n",
    "# Creating the instance of naive bayes\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "# Predict the testing data with the current training data\n",
    "predictions = naive_bayes.predict(testing_data)\n",
    "\n",
    "print('*********************** Predictions: 1 is SPAM, 0 is Not SPAM****************************')\n",
    "print(predictions)\n",
    "for i, val in enumerate(predictions): \n",
    "    print('SPAM' if val == 1 else 'NOT SPAM')\n",
    "    print(X_test_custom[i])\n",
    "    print('----------------------------------------')\n",
    "print('***************************************************')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('*********************** Accuracy Model ****************************')\n",
    "print('Accuracy score: ', format(accuracy_score(Y_test_custom, predictions)))\n",
    "print('Precision score: ', format(precision_score(Y_test_custom, predictions)))\n",
    "print('Recall score: ', format(recall_score(Y_test_custom, predictions)))\n",
    "print('F1 score: ', format(f1_score(Y_test_custom, predictions)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
